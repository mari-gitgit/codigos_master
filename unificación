import os
import re
from dataclasses import replace
import unicodedata
import pandas as pd
import numpy as np

#Configuración
DATA_DIR=r"C:\Users\paper\Desktop\Master"
TD_XLSX=r"C:\Users\paper\Documents\Deserción universidades\articles-415244_recurso_7.xlsx"
OUT_DIR=r"C:\Users\paper\Desktop\Master"
os.makedirs(OUT_DIR,exist_ok=True)

#CSV esperados
CSV_FILES=[
    "escolaridad_municipios_tidy.csv",
    "servicios_publicos_por_departamento_limpio.csv",
    "ciudades_capitales_pobreza.csv",
    "IP_Sexo_ciudades_capitales.csv",
    "IP_Sexo_grandes_dominios.csv",
    "manzanas_estrato_por_municipio.csv",
    "pobreza_grandes_dominios_pct.csv",
    "proyección_poblacion.csv",
    "Tasas_Empleo_Departamentos_LIMPIO.csv",
    "tipos_ruralidad.csv"
]

#Año Objetivo 2023
TARGET_YEAR=2023
TARGET_LEVEL="Total General"

#HELPERS
def normalize_text(s:str) -> str:
    if s is None:
        return ""
    s=str(s).strip()
    s=unicodedata.normalize("NFKD",s).encode("ascii","ignore").decode("ascii")
    s=re.sub(r"\s+"," ",s)
    return s.strip()

def normalize_col(c:str) -> str:
    c=normalize_text(c).lower()
    c=replace("%","pct")
    c=re.sub(r"[^a-z0-9_ ]+","",c)
    c=replace(" ","_")
    c=re.sub(r"_+","_",c)
    return c

def read_csv_robust(path:str) -> pd.DataFrame:
    #Intentamos separadores y encodings comunes
    for enc in ("utf-8-sig","utf-8","latin-1"):
        for sep in (",",";","\t"):
            try:
                df=pd.read_csv(path,sep=sep,encoding=enc)
                if df.shape[1]>=2:
                    return df
            except Exception:
                pass
    return pd.read_csv(path)

def pick_col(df:pd.Dataframe,candidates):
    cols=list(df.columns)
    cset={c.lower():c for c in cols}
    for cand in candidates:
        if cand.lower() in cset:
            return cset[cand.lower()]
    for cand in candidates:
        for c in cols:
            if cand.lower() in c.lower():
                return c
    return None

def standarize_geo(df:pd.DataFrame) -> pd.DataFrame:
    #Intenta dejar columnas de localización y limpia strings
    df=df.copy()
    df.columns=[normalize_col(c) for c in df.columns]

    dept_col=pick_col(df,["departamento","depto","nombre_departamento"])
    muni_col=pick_col(df,["municipio","nombre_municipio","ciudad","área"])

    if dept_col is None and muni_col is None:
        return df #no se puede estandarizar

    if dept_col is not None:
        df["departamento"]=df[dept_col].astype(str).map(normalize_text)

    if muni_col is not None:
        df["municipio"]=df[muni_col].astype(str).map(normalize_text)

    #Limpieza de NaN
    for col in ["departamento","municipio"]:
        if col in df.columns:
            df[col]=df[col].replace({"Nan":np.nan,"nan":np.nan,"None":np.nan,"":np.nan})

    return df

def safe_numeric(series):
    return pd.to_numeric(series, errors="coerce")

#------- Carga y Limpieza base de los CSV
frames={}
for f in CSV_FILES:
    path=os.path.join(DATA_DIR,f)
    if not os.path.exists(path):
        print(f"[WARN] No existe: {path}")
        continue

    df=read_csv_robust(path)
    df=standarize_geo(df)

    print(f"\n=={f}==")
    print("shape: ",df.shape)
    print("cols: ",list(df.columns)[:30])

    frames[f]=df

if not frames:
    raise RuntimeError("No se cargó ningún CSV. Revisa DATA_DIR y la lista CSV_FILES.")

#------------------ TRANSFORMACIONES
wide_parts=[]

#Servicios Públicos
f="servicios_publicos_por_departamento_limpio.csv"
if f in frames:
    sp=frames[f].copy()
    #Columnas típicas
    servicio_col=pick_col(sp,["Servicio"])
    resp_col    =pick_col(sp,["Respuesta"])
    pct_col     =pick_col(sp,["Porcentaje"])
    casos_col   =pick_col(sp,["Casos"])

    if pct_col:
        sp[pct_col]=safe_numeric(sp[pct_col])

    #Nos quedamos con pocentaje por servicio y respuesta
    if "Departamento" in sp.columns and servicio_col and resp_col and pct_col:
        tmp=sp.dropna(subset=["Departamento",servicio_col,resp_col]).copy()
        tmp["var"]=(
            tmp[servicio_col].astype(str).map(normalize_text)
            + "_"+tmp[resp_col].astype(str).map(normalize_text)
        )
        piv=tmp.pivot_table(index="Departamento",columns="var",values=pct_col,aggfunc="mean")
        piv.columns=[f"servpub_pct_{normalize_col(c)}" for c in piv.columns]
        piv=piv.reset_index()
        wide_parts.append(piv)

#Escolaridad
f="escolaridad_municipios_tidy.csv"
escolaridad_mun_wide=None
if f in frames:
    esc=frames[f].copy()

    tipo_col=pick_col(esc,["tipo_estudio"])
    edad_col=pick_col(esc,["grupo_edad"])
    val_col =pick_col(esc,["valor"])

    if val_col:
        esc[val_col]=safe_numeric(esc[val_col])

    if "Departamento" in esc.columns and "Municipio" in esc.columns and tipo_col and edad_col and val_col:
        tmp=esc.dropna(subset=["Departamento","Municipio",tipo_col,edad_col]).copy()
        tmp["var"]=(
            tmp[tipo_col].astype(str).map(normalize_text)
            + "_"+tmp[edad_col].astype(str).map(normalize_text)
        )
        piv_mun=tmp.pivot_table(index=["Departamento","Municipio"],columns="var",values=val_col,aggfunc="mean")
        piv_mun.columns=[f"escolar_{normalize_col(c)}" for c in piv_mun.columns]
        piv_mun=piv_mun.reset_index()
        escolaridad_mun_wide=piv_mun

        #Agregamos a departamento
        piv_dep=piv_mun.drop(columns=["Municipio"]).groupby("Departamento",as_index=False).mean(numeric_only=True)
        wide_parts.append(piv_dep)

#Estrato por municipio
f="manzanas_estrato_por_municipio.csv"
if f in frames:
    est=frames[f].copy()
    estrato_col=pick_col(est,"ESTRATO_PREDOMINANTE_INT")
    val_col=pick_col(est,"n_manzanas")

    if val_col:
        est[val_col]=safe_numeric(est[val_col])

    if "DEPTO" in est.columns and "MPIO" in est.columns and estrato_col and val_col:
        tmp=est.dropna(subset=["DEPTO","MPIO",estrato_col]).copy()
        tmp["var"]=tmp[estrato_col].astype(str).map(normalize_text)
        piv_mun=tmp.pivot_table(index=["DEPTO","MPIO"],columns="var",values=val_col,aggfunc="mean")
        piv_mun.columns=[f"estrato_{normalize_col(c)}" for c in piv_mun.columns]
        piv_mun=piv_mun.reset_index()

        piv_dep=piv_mun.drop(columns=["MPIO"]).groupby("DEPTO",as_index=False).mean(numeric_only=True)
        wide_parts.append(piv_dep)

#Ruralidad
f=""
